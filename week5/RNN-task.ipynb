{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "start_token = \" \"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token+name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n samples =  7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print ('n samples = ',len(names))\n",
    "for x in names[::1000]:\n",
    "    print (x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length = 16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18190045f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len,names))\n",
    "print(\"max length =\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len,names)),bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need next to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens =  55\n"
     ]
    }
   ],
   "source": [
    "#all unique characters go here\n",
    "tokens = set(''.join(names))\n",
    "\n",
    "tokens = list(tokens)\n",
    "\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens = ',n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_id = {}\n",
    "for i in range(n_tokens):\n",
    "    token_to_id[tokens[i]] = i\n",
    "###YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems alright!\n"
     ]
    }
   ],
   "source": [
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
    "\n",
    "for i in range(n_tokens):\n",
    "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(names,max_len=None,pad=0,dtype='int32'):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len,names))\n",
    "    names_ix = np.zeros([len(names),max_len],dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get,names[i]))\n",
    "        names_ix[i,:len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[14 47 40 32 31 32 10 34  0]\n",
      " [14  8 34 21 49 29  0  0  0]\n",
      " [14  7 49  6 22 22  6 10  0]\n",
      " [14  8  6 21 33 32 48 48 10]]\n"
     ]
    }
   ],
   "source": [
    "#Example: cast 4 random names to matrices, pad with zeros\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=480>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Concatenate,Dense,Embedding\n",
    "\n",
    "rnn_num_units = 64\n",
    "embedding_size = 16\n",
    "\n",
    "#Let's create layers for our recurrent network\n",
    "#Note: we create layers but we don't \"apply\" them yet\n",
    "embed_x = Embedding(n_tokens,embedding_size) # an embedding layer that converts character ids into embeddings\n",
    "\n",
    "\n",
    "#a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(rnn_num_units,activation='relu')###YOUR CODE HERE\n",
    "\n",
    "#a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(n_tokens, activation='softmax')###YOUR CODE HERE \n",
    "\n",
    "#Note: please either set the correct activation to Dense or write it manually in rnn_one_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces next state and output\n",
    "    given prev input and previous state.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    Follow inline isntructions to complete the function.\n",
    "    \"\"\"\n",
    "    #convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t,[-1,1]))[:,0]\n",
    "    \n",
    "    #concatenate x embedding and previous h state\n",
    "    x_and_h = tf.concat([x_t_emb,h_t],1)###YOUR CODE HERE\n",
    "    \n",
    "    #compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h)###YOUR CODE HERE\n",
    "    \n",
    "    #get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next)###YOUR CODE HERE\n",
    "    \n",
    "    return output_probas,h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN loop\n",
    "\n",
    "Once rnn_one_step is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder('int32',(MAX_LENGTH,None))\n",
    "batch_size = tf.shape(input_sequence)[1]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size,rnn_num_units]) #initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[t]\n",
    "    probas_next,h_next = rnn_one_step(x_t,h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "predicted_probas = tf.stack(predicted_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_matrix = tf.reshape(predicted_probas[:-1],[-1,len(tokens)])\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[1:],[-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.objectives import categorical_crossentropy\n",
    "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix))\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "s = keras.backend.get_session()\n",
    "s.run(tf.global_variables_initializer())\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181ea80e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names,32),max_len=MAX_LENGTH)\n",
    "    loss_i,_ = s.run([loss,optimize],{input_sequence:batch})\n",
    "    \n",
    "    \n",
    "    history.append(loss_i)\n",
    "    if (i+1)%100==0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.0089965,\n",
       " 4.0013394,\n",
       " 3.99206,\n",
       " 3.9825857,\n",
       " 3.973828,\n",
       " 3.965831,\n",
       " 3.9553533,\n",
       " 3.9464672,\n",
       " 3.9339478,\n",
       " 3.9159317,\n",
       " 3.9042964,\n",
       " 3.8772156,\n",
       " 3.8566034,\n",
       " 3.837055,\n",
       " 3.8008091,\n",
       " 3.7554774,\n",
       " 3.708013,\n",
       " 3.6151843,\n",
       " 3.562453,\n",
       " 3.442383,\n",
       " 3.2898357,\n",
       " 3.1005304,\n",
       " 2.8870556,\n",
       " 2.6426828,\n",
       " 2.3994787,\n",
       " 2.174465,\n",
       " 2.0130765,\n",
       " 1.8426274,\n",
       " 1.8198516,\n",
       " 1.7904636,\n",
       " 1.7316638,\n",
       " 1.5853665,\n",
       " 1.7182611,\n",
       " 1.7739769,\n",
       " 1.6238024,\n",
       " 1.748817,\n",
       " 1.6943053,\n",
       " 1.5231577,\n",
       " 1.6069791,\n",
       " 1.6794447,\n",
       " 1.6696583,\n",
       " 1.6421188,\n",
       " 1.8760468,\n",
       " 1.541376,\n",
       " 1.600484,\n",
       " 1.5678183,\n",
       " 1.6141843,\n",
       " 1.6753596,\n",
       " 1.633902,\n",
       " 1.6926194,\n",
       " 1.628227,\n",
       " 1.4972672,\n",
       " 1.5348307,\n",
       " 1.4452975,\n",
       " 1.4611176,\n",
       " 1.682045,\n",
       " 1.4243397,\n",
       " 1.6001854,\n",
       " 1.452534,\n",
       " 1.5311701,\n",
       " 1.5848824,\n",
       " 1.4699824,\n",
       " 1.5121443,\n",
       " 1.6318034,\n",
       " 1.4470085,\n",
       " 1.5895058,\n",
       " 1.6186198,\n",
       " 1.3841245,\n",
       " 1.4014379,\n",
       " 1.5278409,\n",
       " 1.495708,\n",
       " 1.4522678,\n",
       " 1.5144155,\n",
       " 1.4051269,\n",
       " 1.5425949,\n",
       " 1.469489,\n",
       " 1.4204258,\n",
       " 1.4294065,\n",
       " 1.5907867,\n",
       " 1.4405804,\n",
       " 1.4556259,\n",
       " 1.6168082,\n",
       " 1.4368596,\n",
       " 1.405341,\n",
       " 1.5963094,\n",
       " 1.4684062,\n",
       " 1.5476636,\n",
       " 1.4565275,\n",
       " 1.4281135,\n",
       " 1.454332,\n",
       " 1.4467866,\n",
       " 1.4841187,\n",
       " 1.3839778,\n",
       " 1.410941,\n",
       " 1.3924421,\n",
       " 1.4121374,\n",
       " 1.523231,\n",
       " 1.6346126,\n",
       " 1.481068,\n",
       " 1.3351152,\n",
       " 1.4433511,\n",
       " 1.417734,\n",
       " 1.3986341,\n",
       " 1.3549589,\n",
       " 1.4008868,\n",
       " 1.5028037,\n",
       " 1.3840896,\n",
       " 1.3369766,\n",
       " 1.4348874,\n",
       " 1.4489647,\n",
       " 1.3602084,\n",
       " 1.5188698,\n",
       " 1.3987634,\n",
       " 1.3718426,\n",
       " 1.4828924,\n",
       " 1.5589862,\n",
       " 1.4473938,\n",
       " 1.5077078,\n",
       " 1.4938837,\n",
       " 1.4355121,\n",
       " 1.3689829,\n",
       " 1.3545547,\n",
       " 1.4358506,\n",
       " 1.3847833,\n",
       " 1.4414752,\n",
       " 1.2959902,\n",
       " 1.359966,\n",
       " 1.434492,\n",
       " 1.3312516,\n",
       " 1.3034369,\n",
       " 1.4797839,\n",
       " 1.3562505,\n",
       " 1.4370707,\n",
       " 1.3640239,\n",
       " 1.3162416,\n",
       " 1.3792361,\n",
       " 1.2975318,\n",
       " 1.2572396,\n",
       " 1.3116984,\n",
       " 1.2948174,\n",
       " 1.3370664,\n",
       " 1.274988,\n",
       " 1.336822,\n",
       " 1.4354062,\n",
       " 1.3571066,\n",
       " 1.4628404,\n",
       " 1.3690314,\n",
       " 1.2579142,\n",
       " 1.2168796,\n",
       " 1.4254435,\n",
       " 1.3046142,\n",
       " 1.397964,\n",
       " 1.3706452,\n",
       " 1.4211341,\n",
       " 1.2950966,\n",
       " 1.323527,\n",
       " 1.3538762,\n",
       " 1.3061557,\n",
       " 1.3441132,\n",
       " 1.226846,\n",
       " 1.1909121,\n",
       " 1.2499158,\n",
       " 1.4618825,\n",
       " 1.3969073,\n",
       " 1.3742636,\n",
       " 1.2989686,\n",
       " 1.3995565,\n",
       " 1.2709037,\n",
       " 1.2241433,\n",
       " 1.413297,\n",
       " 1.343547,\n",
       " 1.2476262,\n",
       " 1.3013508,\n",
       " 1.2357618,\n",
       " 1.3906237,\n",
       " 1.2657666,\n",
       " 1.2389557,\n",
       " 1.3976201,\n",
       " 1.2800274,\n",
       " 1.3767471,\n",
       " 1.3847371,\n",
       " 1.3623639,\n",
       " 1.2854253,\n",
       " 1.3153032,\n",
       " 1.2923169,\n",
       " 1.3175735,\n",
       " 1.2048874,\n",
       " 1.3601705,\n",
       " 1.2812121,\n",
       " 1.249049,\n",
       " 1.4760078,\n",
       " 1.2915739,\n",
       " 1.2902367,\n",
       " 1.4475428,\n",
       " 1.2760679,\n",
       " 1.2343273,\n",
       " 1.1753247,\n",
       " 1.2813408,\n",
       " 1.3997923,\n",
       " 1.2626309,\n",
       " 1.257603,\n",
       " 1.4537327,\n",
       " 1.23843,\n",
       " 1.0869807,\n",
       " 1.2149696,\n",
       " 1.2159592,\n",
       " 1.3889129,\n",
       " 1.2972488,\n",
       " 1.275297,\n",
       " 1.2267964,\n",
       " 1.3142301,\n",
       " 1.2184908,\n",
       " 1.4569649,\n",
       " 1.3262239,\n",
       " 1.270754,\n",
       " 1.304137,\n",
       " 1.2542945,\n",
       " 1.2036959,\n",
       " 1.4769859,\n",
       " 1.1784775,\n",
       " 1.174292,\n",
       " 1.3898656,\n",
       " 1.2040614,\n",
       " 1.3111874,\n",
       " 1.1853333,\n",
       " 1.2468303,\n",
       " 1.2627012,\n",
       " 1.3103896,\n",
       " 1.2031337,\n",
       " 1.2481104,\n",
       " 1.271777,\n",
       " 1.332783,\n",
       " 1.2092633,\n",
       " 1.2642436,\n",
       " 1.1120092,\n",
       " 1.2788665,\n",
       " 1.1787568,\n",
       " 1.3134041,\n",
       " 1.3499734,\n",
       " 1.2620603,\n",
       " 1.1609397,\n",
       " 1.2616352,\n",
       " 1.1370757,\n",
       " 1.3260173,\n",
       " 1.2427294,\n",
       " 1.1995323,\n",
       " 1.2122343,\n",
       " 1.2581065,\n",
       " 1.2412289,\n",
       " 1.1798851,\n",
       " 1.2426168,\n",
       " 1.2374015,\n",
       " 1.1937809,\n",
       " 1.1854349,\n",
       " 1.2374398,\n",
       " 1.1848532,\n",
       " 1.186815,\n",
       " 1.1803412,\n",
       " 1.14334,\n",
       " 1.244603,\n",
       " 1.14192,\n",
       " 1.141925,\n",
       " 1.2157186,\n",
       " 1.1363665,\n",
       " 1.1288054,\n",
       " 1.184154,\n",
       " 1.2662158,\n",
       " 1.2486378,\n",
       " 1.2579799,\n",
       " 1.3561264,\n",
       " 1.2765604,\n",
       " 1.2528954,\n",
       " 1.1882647,\n",
       " 1.1537548,\n",
       " 1.1869779,\n",
       " 1.1956867,\n",
       " 1.1657898,\n",
       " 1.099034,\n",
       " 1.181427,\n",
       " 1.1903428,\n",
       " 1.1883184,\n",
       " 1.2415414,\n",
       " 1.1733854,\n",
       " 1.2094688,\n",
       " 1.1347563,\n",
       " 1.1722623,\n",
       " 1.2751557,\n",
       " 1.1224121,\n",
       " 1.2798207,\n",
       " 1.1352702,\n",
       " 1.126891,\n",
       " 1.2672395,\n",
       " 1.1241119,\n",
       " 1.2073363,\n",
       " 1.1621735,\n",
       " 1.111998,\n",
       " 1.2233346,\n",
       " 1.2318901,\n",
       " 1.0585908,\n",
       " 1.1915158,\n",
       " 1.0886897,\n",
       " 1.1876625,\n",
       " 1.1022793,\n",
       " 1.3030635,\n",
       " 1.1492857,\n",
       " 1.130967,\n",
       " 1.2057574,\n",
       " 1.2707298,\n",
       " 1.2721539,\n",
       " 1.0868604,\n",
       " 1.1260145,\n",
       " 1.1267942,\n",
       " 1.2098725,\n",
       " 1.238748,\n",
       " 1.2844609,\n",
       " 1.1760824,\n",
       " 1.086691,\n",
       " 1.1955355,\n",
       " 1.1675531,\n",
       " 1.1400412,\n",
       " 1.0854267,\n",
       " 1.301771,\n",
       " 1.1856773,\n",
       " 1.1685098,\n",
       " 1.0979594,\n",
       " 1.348854,\n",
       " 1.1239731,\n",
       " 1.1678121,\n",
       " 1.2534335,\n",
       " 1.1396787,\n",
       " 1.0973003,\n",
       " 1.1170055,\n",
       " 1.1328269,\n",
       " 1.1981432,\n",
       " 1.3409307,\n",
       " 1.0878787,\n",
       " 1.1745894,\n",
       " 1.0950621,\n",
       " 1.1398854,\n",
       " 1.1928213,\n",
       " 1.2136371,\n",
       " 1.1829807,\n",
       " 1.0956764,\n",
       " 1.1680094,\n",
       " 1.1372521,\n",
       " 1.1030695,\n",
       " 1.2237899,\n",
       " 1.2707484,\n",
       " 1.1524218,\n",
       " 1.1391786,\n",
       " 1.1341251,\n",
       " 1.2335992,\n",
       " 1.1653761,\n",
       " 1.2039207,\n",
       " 1.1856751,\n",
       " 1.1285197,\n",
       " 1.1057551,\n",
       " 1.1709996,\n",
       " 1.1459098,\n",
       " 1.1038147,\n",
       " 1.0874455,\n",
       " 1.1919599,\n",
       " 1.1924615,\n",
       " 1.1823163,\n",
       " 1.1770288,\n",
       " 1.130291,\n",
       " 1.067995,\n",
       " 1.1100051,\n",
       " 1.1836306,\n",
       " 1.2797627,\n",
       " 1.1655364,\n",
       " 1.1189908,\n",
       " 1.1027015,\n",
       " 1.1380486,\n",
       " 1.1330205,\n",
       " 1.0982026,\n",
       " 1.1083982,\n",
       " 1.1674954,\n",
       " 1.2019725,\n",
       " 1.2390121,\n",
       " 1.1261035,\n",
       " 1.1896807,\n",
       " 1.0530483,\n",
       " 1.1692985,\n",
       " 1.1770098,\n",
       " 1.097739,\n",
       " 1.1753545,\n",
       " 1.2096466,\n",
       " 1.1098536,\n",
       " 1.1494681,\n",
       " 1.1769463,\n",
       " 1.0986836,\n",
       " 1.192953,\n",
       " 1.2201273,\n",
       " 1.1274358,\n",
       " 1.138097,\n",
       " 1.1632203,\n",
       " 1.106084,\n",
       " 1.1300776,\n",
       " 1.1575189,\n",
       " 1.1724544,\n",
       " 1.1216121,\n",
       " 1.106249,\n",
       " 1.0585537,\n",
       " 1.1280138,\n",
       " 1.1531726,\n",
       " 1.1466342,\n",
       " 1.1883718,\n",
       " 1.1898905,\n",
       " 1.217734,\n",
       " 1.1680781,\n",
       " 1.1229573,\n",
       " 1.1424642,\n",
       " 1.1574852,\n",
       " 1.1490855,\n",
       " 1.0715783,\n",
       " 1.1350335,\n",
       " 1.1436135,\n",
       " 1.166804,\n",
       " 1.1297528,\n",
       " 1.2021687,\n",
       " 1.245277,\n",
       " 1.3247274,\n",
       " 1.2024924,\n",
       " 1.145386,\n",
       " 1.1400093,\n",
       " 1.2036082,\n",
       " 1.0803887,\n",
       " 1.2498461,\n",
       " 1.187128,\n",
       " 1.1584548,\n",
       " 1.0863134,\n",
       " 1.0800186,\n",
       " 1.1160512,\n",
       " 1.0728453,\n",
       " 1.1528708,\n",
       " 1.1925933,\n",
       " 1.0843828,\n",
       " 1.1931412,\n",
       " 1.138517,\n",
       " 1.0790185,\n",
       " 1.2106702,\n",
       " 1.1411911,\n",
       " 1.2025505,\n",
       " 1.0537715,\n",
       " 1.2567828,\n",
       " 1.1318179,\n",
       " 1.1254681,\n",
       " 1.0808923,\n",
       " 1.2314135,\n",
       " 1.1857358,\n",
       " 1.1509833,\n",
       " 1.1040418,\n",
       " 1.0210165,\n",
       " 1.04119,\n",
       " 1.2110232,\n",
       " 1.1625063,\n",
       " 1.2005036,\n",
       " 1.1189908,\n",
       " 1.0966815,\n",
       " 1.1345605,\n",
       " 1.0927088,\n",
       " 1.1252455,\n",
       " 1.0514773,\n",
       " 1.0790246,\n",
       " 1.0904148,\n",
       " 1.1301819,\n",
       " 1.1680171,\n",
       " 1.1733766,\n",
       " 1.124871,\n",
       " 1.1171314,\n",
       " 1.0675223,\n",
       " 1.109697,\n",
       " 1.0721812,\n",
       " 1.2692878,\n",
       " 1.092598,\n",
       " 1.1293683,\n",
       " 1.0946387,\n",
       " 1.1822301,\n",
       " 1.1293558,\n",
       " 1.1625576,\n",
       " 1.1635437,\n",
       " 1.1106257,\n",
       " 1.2286909,\n",
       " 1.0926529,\n",
       " 0.96989316,\n",
       " 1.1528096,\n",
       " 1.1121902,\n",
       " 1.0827383,\n",
       " 1.156705,\n",
       " 1.0238421,\n",
       " 1.197123,\n",
       " 1.1755033,\n",
       " 1.2135317,\n",
       " 1.0948108,\n",
       " 1.0866698,\n",
       " 1.3455393,\n",
       " 1.0626695,\n",
       " 1.218664,\n",
       " 1.0796005,\n",
       " 1.055907,\n",
       " 1.2262437,\n",
       " 1.1434741,\n",
       " 1.1340832,\n",
       " 1.172154,\n",
       " 1.1113963,\n",
       " 1.0667002,\n",
       " 1.1483399,\n",
       " 0.9934413,\n",
       " 1.0066876,\n",
       " 1.106218,\n",
       " 1.2634562,\n",
       " 1.0611603,\n",
       " 1.1097459,\n",
       " 1.0671916,\n",
       " 1.1852955,\n",
       " 1.1108676,\n",
       " 1.1410831,\n",
       " 1.2056633,\n",
       " 1.0583491,\n",
       " 1.135531,\n",
       " 1.1472827,\n",
       " 1.1287842,\n",
       " 1.1538335,\n",
       " 1.127225,\n",
       " 1.1453209,\n",
       " 1.0516021,\n",
       " 1.0822507,\n",
       " 1.1649244,\n",
       " 1.1608697,\n",
       " 1.1259806,\n",
       " 1.1294376,\n",
       " 1.0961479,\n",
       " 1.0905617,\n",
       " 1.200187,\n",
       " 1.0734475,\n",
       " 1.1010087,\n",
       " 1.0967882,\n",
       " 1.0024284,\n",
       " 1.0608659,\n",
       " 1.0435532,\n",
       " 1.0779902,\n",
       " 1.0141106,\n",
       " 1.0191958,\n",
       " 1.202122,\n",
       " 1.1034207,\n",
       " 1.1306036,\n",
       " 1.0841807,\n",
       " 1.1194605,\n",
       " 1.0916203,\n",
       " 1.0584902,\n",
       " 1.1144241,\n",
       " 1.0530739,\n",
       " 1.1003797,\n",
       " 1.1238722,\n",
       " 1.0330886,\n",
       " 1.2103418,\n",
       " 1.1659791,\n",
       " 1.1305954,\n",
       " 1.1783968,\n",
       " 1.1009789,\n",
       " 1.0742717,\n",
       " 1.2009048,\n",
       " 1.1029973,\n",
       " 1.0970116,\n",
       " 1.1433545,\n",
       " 1.1258708,\n",
       " 1.258762,\n",
       " 1.2545314,\n",
       " 1.1169454,\n",
       " 1.1177348,\n",
       " 1.0930761,\n",
       " 1.1023097,\n",
       " 1.0865299,\n",
       " 1.0779526,\n",
       " 1.0840899,\n",
       " 1.063496,\n",
       " 1.0880729,\n",
       " 1.0718002,\n",
       " 1.1058332,\n",
       " 1.1930565,\n",
       " 1.1051602,\n",
       " 1.0103935,\n",
       " 1.0980489,\n",
       " 1.2272671,\n",
       " 1.1741388,\n",
       " 1.1186395,\n",
       " 1.0721346,\n",
       " 1.083076,\n",
       " 1.1216662,\n",
       " 1.1122775,\n",
       " 1.1606917,\n",
       " 1.1227195,\n",
       " 1.1395414,\n",
       " 1.0978439,\n",
       " 1.1042824,\n",
       " 1.0659318,\n",
       " 1.2092112,\n",
       " 1.0474128,\n",
       " 1.0734459,\n",
       " 1.0822675,\n",
       " 1.1421278,\n",
       " 1.1170042,\n",
       " 1.1300049,\n",
       " 1.0938531,\n",
       " 1.0718951,\n",
       " 1.1257144,\n",
       " 1.1620235,\n",
       " 1.1191051,\n",
       " 1.0651209,\n",
       " 1.1624514,\n",
       " 1.1936158,\n",
       " 1.0506349,\n",
       " 1.0080476,\n",
       " 1.0914158,\n",
       " 1.0682125,\n",
       " 1.0802078,\n",
       " 1.0947671,\n",
       " 1.1808449,\n",
       " 1.0491617,\n",
       " 1.1535814,\n",
       " 1.0693539,\n",
       " 1.1790326,\n",
       " 1.1551418,\n",
       " 1.193545,\n",
       " 1.1044176,\n",
       " 1.1944827,\n",
       " 1.1264015,\n",
       " 1.1052887,\n",
       " 1.1272533,\n",
       " 1.1308373,\n",
       " 1.1008991,\n",
       " 1.1280024,\n",
       " 1.0497736,\n",
       " 1.121497,\n",
       " 1.1524026,\n",
       " 1.2251205,\n",
       " 1.216578,\n",
       " 1.1156026,\n",
       " 1.133924,\n",
       " 1.0681814,\n",
       " 1.0511585,\n",
       " 1.1186275,\n",
       " 1.1509469,\n",
       " 1.0526367,\n",
       " 1.0610123,\n",
       " 1.0939671,\n",
       " 1.0936744,\n",
       " 1.1484376,\n",
       " 1.1292747,\n",
       " 1.2554848,\n",
       " 0.9772904,\n",
       " 1.0893744,\n",
       " 1.022141,\n",
       " 1.1790525,\n",
       " 1.1395333,\n",
       " 1.1069125,\n",
       " 1.0553378,\n",
       " 1.0038241,\n",
       " 1.2112503,\n",
       " 1.1115532,\n",
       " 1.1358944,\n",
       " 1.1264776,\n",
       " 1.0908703,\n",
       " 1.088961,\n",
       " 1.119718,\n",
       " 1.0292765,\n",
       " 1.050329,\n",
       " 1.0831808,\n",
       " 1.05075,\n",
       " 1.0694199,\n",
       " 1.2271657,\n",
       " 1.1393379,\n",
       " 1.1172945,\n",
       " 1.1228889,\n",
       " 1.0291225,\n",
       " 1.0189568,\n",
       " 1.1489743,\n",
       " 1.0610371,\n",
       " 1.0478939,\n",
       " 1.1581271,\n",
       " 1.0244718,\n",
       " 1.038985,\n",
       " 1.0612301,\n",
       " 1.0776297,\n",
       " 1.0486623,\n",
       " 1.0653228,\n",
       " 1.0881813,\n",
       " 1.1934128,\n",
       " 1.1423243,\n",
       " 1.0870908,\n",
       " 1.2145795,\n",
       " 1.1807038,\n",
       " 1.1637,\n",
       " 1.0424107,\n",
       " 1.2302068,\n",
       " 1.1584042,\n",
       " 1.1242864,\n",
       " 1.0715319,\n",
       " 1.0031177,\n",
       " 1.1075832,\n",
       " 1.0781658,\n",
       " 1.1267836,\n",
       " 1.0345366,\n",
       " 1.1123769,\n",
       " 1.1380925,\n",
       " 1.0786194,\n",
       " 1.0204155,\n",
       " 1.1446121,\n",
       " 1.1174372,\n",
       " 1.0949216,\n",
       " 1.1012357,\n",
       " 1.0690068,\n",
       " 1.1236798,\n",
       " 1.0218167,\n",
       " 1.0996951,\n",
       " 1.2574977,\n",
       " 1.1085852,\n",
       " 1.1504078,\n",
       " 1.0443016,\n",
       " 1.0899312,\n",
       " 1.1599604,\n",
       " 0.98897326,\n",
       " 1.1032547,\n",
       " 1.0277767,\n",
       " 1.0001936,\n",
       " 1.0953511,\n",
       " 1.1133687,\n",
       " 1.0926006,\n",
       " 1.052089,\n",
       " 1.0662498,\n",
       " 1.1260936,\n",
       " 1.0977958,\n",
       " 1.0643871,\n",
       " 1.0736387,\n",
       " 1.01276,\n",
       " 1.1270986,\n",
       " 1.1240845,\n",
       " 1.116586,\n",
       " 1.0385853,\n",
       " 1.2244934,\n",
       " 1.0282568,\n",
       " 0.98680466,\n",
       " 1.0684514,\n",
       " 1.0507197,\n",
       " 1.0868238,\n",
       " 1.1727315,\n",
       " 1.1218988,\n",
       " 1.1813514,\n",
       " 0.97419685,\n",
       " 1.0280414,\n",
       " 1.1474828,\n",
       " 1.0570979,\n",
       " 1.0493821,\n",
       " 1.0170323,\n",
       " 1.0566186,\n",
       " 1.1346714,\n",
       " 1.0435731,\n",
       " 1.0442826,\n",
       " 0.9721166,\n",
       " 1.0068249,\n",
       " 1.0169587,\n",
       " 1.0704256,\n",
       " 1.0511428,\n",
       " 1.0539244,\n",
       " 1.0781759,\n",
       " 1.0668805,\n",
       " 1.1008748,\n",
       " 1.1986004,\n",
       " 1.1194264,\n",
       " 1.1512825,\n",
       " 1.050489,\n",
       " 1.0577598,\n",
       " 1.0410155,\n",
       " 1.1685244,\n",
       " 1.0573199,\n",
       " 1.1658015,\n",
       " 1.1162281,\n",
       " 1.0452888,\n",
       " 1.1225024,\n",
       " 1.0406799,\n",
       " 1.0334264,\n",
       " 1.0145758,\n",
       " 1.1263824,\n",
       " 1.0303026,\n",
       " 0.9857665,\n",
       " 1.1190525,\n",
       " 1.0824913,\n",
       " 1.0314622,\n",
       " 1.001803,\n",
       " 1.1150824,\n",
       " 1.1062617,\n",
       " 1.0447255,\n",
       " 1.0532372,\n",
       " 1.0904163,\n",
       " 1.0808696,\n",
       " 1.0386494,\n",
       " 1.1648598,\n",
       " 1.050543,\n",
       " 1.1500123,\n",
       " 1.044984,\n",
       " 1.1275232,\n",
       " 1.1379247,\n",
       " 1.0571095,\n",
       " 1.0737805,\n",
       " 1.0142051,\n",
       " 1.0655837,\n",
       " 1.0390232,\n",
       " 1.1012138,\n",
       " 1.1799636,\n",
       " 1.1383064,\n",
       " 1.0592811,\n",
       " 1.0865419,\n",
       " 1.0944707,\n",
       " 1.0634626,\n",
       " 1.0964799,\n",
       " 1.1266395,\n",
       " 1.0972763,\n",
       " 1.0775682,\n",
       " 1.1017934,\n",
       " 1.1340567,\n",
       " 1.1338589,\n",
       " 1.0523095,\n",
       " 1.1248089,\n",
       " 1.0803838,\n",
       " 1.0638685,\n",
       " 1.076836,\n",
       " 1.0665623,\n",
       " 1.0889581,\n",
       " 1.0969055,\n",
       " 1.0833747,\n",
       " 1.0890293,\n",
       " 1.0315784,\n",
       " 1.1238686,\n",
       " 1.1099465,\n",
       " 1.0130999,\n",
       " 1.1040593,\n",
       " 1.03191,\n",
       " 1.062406,\n",
       " 1.1456949,\n",
       " 1.0922414,\n",
       " 1.2185613,\n",
       " 1.0837435,\n",
       " 1.15221,\n",
       " 1.1405858,\n",
       " 1.1662362,\n",
       " 1.1388253,\n",
       " 1.079553,\n",
       " 1.0535904,\n",
       " 1.0119227,\n",
       " 1.1061558,\n",
       " 1.0105606,\n",
       " 0.99901545,\n",
       " 1.0801262,\n",
       " 1.0414435,\n",
       " 1.1807872,\n",
       " 1.1538385,\n",
       " 1.0933217,\n",
       " 1.1174423,\n",
       " 1.0485274,\n",
       " 1.0049024,\n",
       " 1.0470006,\n",
       " 1.0707825,\n",
       " 1.1827006,\n",
       " 1.0787822,\n",
       " 0.98149806,\n",
       " 1.1732581,\n",
       " 1.0095106,\n",
       " 1.1690387,\n",
       " 1.0302835,\n",
       " 1.0488274,\n",
       " 1.0674785,\n",
       " 1.213647,\n",
       " 1.1091822,\n",
       " 1.0583797,\n",
       " 1.07946,\n",
       " 1.0481952,\n",
       " 1.084531,\n",
       " 1.1601225,\n",
       " 1.06406,\n",
       " 1.0839272,\n",
       " 1.1204295,\n",
       " 1.1855315,\n",
       " 1.0508577,\n",
       " 1.0511254,\n",
       " 1.1722176,\n",
       " 1.1013684,\n",
       " 1.1424488,\n",
       " 1.0662096,\n",
       " 1.0691775,\n",
       " 1.0936297,\n",
       " 1.1833678,\n",
       " 1.1011767,\n",
       " 1.1114143,\n",
       " 1.0242575,\n",
       " 1.0623381,\n",
       " 1.1241587,\n",
       " 1.0580289,\n",
       " 1.0220381,\n",
       " 1.1329693,\n",
       " 1.0794907,\n",
       " 0.9927386,\n",
       " 1.1216896,\n",
       " 1.2150747,\n",
       " 1.0020283,\n",
       " 1.1378087,\n",
       " 1.0990951,\n",
       " 1.0248681,\n",
       " 1.116809,\n",
       " 1.0386423,\n",
       " 1.0115647,\n",
       " 1.1039292,\n",
       " 1.1354973,\n",
       " 1.0468307,\n",
       " 1.0923178,\n",
       " 1.0833136,\n",
       " 1.0035131,\n",
       " 1.1189893,\n",
       " 1.0538799,\n",
       " 1.0679836,\n",
       " 1.0274532,\n",
       " 1.078318,\n",
       " 1.0058478,\n",
       " 1.1131765,\n",
       " 1.2036636,\n",
       " 1.1409565,\n",
       " 1.0666713,\n",
       " 1.0994176,\n",
       " 1.062191,\n",
       " 1.0504155,\n",
       " 1.175692,\n",
       " 1.11208,\n",
       " 1.0443631,\n",
       " 1.0236999,\n",
       " 1.13955,\n",
       " 1.0977092,\n",
       " 1.0168854,\n",
       " 1.0564696,\n",
       " 1.1446955,\n",
       " 1.1023288,\n",
       " 1.0966334,\n",
       " 0.96604884,\n",
       " 1.0581707,\n",
       " 1.0366713,\n",
       " 1.1515452,\n",
       " 1.0517627,\n",
       " 1.0694549,\n",
       " 1.0388278,\n",
       " 1.0587636,\n",
       " 1.055422,\n",
       " 1.0983927,\n",
       " 1.063229,\n",
       " 1.036723,\n",
       " 1.0466087,\n",
       " 1.1154772,\n",
       " 1.0501449,\n",
       " 0.98100215,\n",
       " 1.0765711,\n",
       " 1.1545516,\n",
       " 0.99051684,\n",
       " 1.0884389,\n",
       " 1.1391534,\n",
       " 1.0119832,\n",
       " 1.1227338,\n",
       " 1.1394763,\n",
       " 1.0795349,\n",
       " 1.0147609,\n",
       " 1.0243648,\n",
       " 1.1498038,\n",
       " 1.0549065,\n",
       " 1.0422423,\n",
       " 1.1122811,\n",
       " 1.0548818,\n",
       " 1.1094223,\n",
       " 1.1537559,\n",
       " 1.0969678,\n",
       " 0.9866545,\n",
       " 1.0389997,\n",
       " 1.0966731,\n",
       " 1.0656229,\n",
       " 0.9452441,\n",
       " 1.1500547,\n",
       " 1.1413416,\n",
       " 1.0397277,\n",
       " 1.1090614,\n",
       " 1.0689253,\n",
       " 0.98018086,\n",
       " 1.0946612,\n",
       " 1.1084323,\n",
       " 1.0457143,\n",
       " 1.0077915,\n",
       " 1.066973,\n",
       " 1.0752853,\n",
       " 1.0452048,\n",
       " 1.071278,\n",
       " 1.0959377,\n",
       " 1.1471515,\n",
       " 1.0317166,\n",
       " 1.0267467,\n",
       " 1.132861]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = tf.placeholder('int32',(None,))\n",
    "h_t = tf.Variable(np.zeros([1,rnn_num_units],'float32'))\n",
    "\n",
    "next_probs,next_h = rnn_one_step(x_t,h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=' ',max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "        \n",
    "    parameters:\n",
    "        The phrase is set using the variable seed_phrase\n",
    "        The optional input \"N\" is used to set the number of characters of text to predict.     \n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t,h_t.initial_value))\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t,next_h),{x_t:[ix]})\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs,tf.assign(h_t,next_h)],{x_t:[x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens,p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ArtelyVVVVVVVVV\n",
      " TuranphordVVVVV\n",
      " CaagmyhVVVVVVVV\n",
      " RerulinuVVVVVVV\n",
      " BaarticVVVVVVVV\n",
      " BibenVVVVVVVVVV\n",
      " CeleeleVVVVVVVV\n",
      " CorzyaVVVVVVVVV\n",
      " FisneVVVVVVVVVV\n",
      " CinaVVVVVVVVVVV\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TrumpyVVVVVVVVV\n",
      " TrumpeVVVVVVVVV\n",
      " TrumpterdVVVVVV\n",
      " TrumphankyVVVVV\n",
      " TrumpaVVVVVVVVV\n",
      " TrumpeVVVVVVVVV\n",
      " TrumpeVVVVVVVVV\n",
      " TrumponneVVVVVV\n",
      " TrumpursVVVVVVV\n",
      " TrumpislelVVVVV\n",
      " TrumpticeVVVVVV\n",
      " TrumpinVVVVVVVV\n",
      " TrumpanhVVVVVVV\n",
      " TrumpersVVVVVVV\n",
      " TrumpelaVVVVVVV\n",
      " TrumpaVVVVVVVVV\n",
      " TrumpemVVVVVVVV\n",
      " TrumpoVVVVVVVVV\n",
      " TrumpeneVVVVVVV\n",
      " TrumpeaVVVVVVVV\n",
      " TrumpeleVVVVVVV\n",
      " TrumpaVVVVVVVVV\n",
      " TrumpyVVVVVVVVV\n",
      " TrumpeVVVVVVVVV\n",
      " TrumpeVVVVVVVVV\n",
      " TrumpelVVVVVVVV\n",
      " TrumpalVVVVVVVV\n",
      " TrumpiVVVVVVVVV\n",
      " TrumpaVVVVVVVVV\n",
      " TrumpyVVVVVVVVV\n",
      " TrumpintaVVVVVV\n",
      " TrumpiaVVVVVVVV\n",
      " TrumpeVVVVVVVVV\n",
      " TrumphaVVVVVVVV\n",
      " TrumpadVVVVVVVV\n",
      " TrumphyleraVVVV\n",
      " TrumperneVVVVVV\n",
      " TrumpaVVVVVVVVV\n",
      " TrumporVVVVVVVV\n",
      " TrumpeVVVVVVVVV\n",
      " TrumpVVVVVVVVVV\n",
      " TrumpaVVVVVVVVV\n",
      " TrumpeVVVVVVVVV\n",
      " TrumpaVVVVVVVVV\n",
      " TrumpthrheVVVVV\n",
      " TrumparVVVVVVVV\n",
      " TrumpeVVVVVVVVV\n",
      " TrumpealaVVVVVV\n",
      " TrumparaVVVVVVV\n",
      " TrumpennhVVVVVV\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit to coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in range(25)]\n",
    "submission = (history,samples)\n",
    "submit_char_rnn(submission, 'qiz216@outlook.com', '83fl1vplp3Kv6TpE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it out!\n",
    "\n",
    "__Disclaimer:__ This assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* Ikea catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from keras, there's also a friendly tensorflow API for recurrent neural nets. It's based around the symbolic loop function (aka [scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-f5c9934ac93f>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-f5c9934ac93f>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    print predicted_probas.eval({input_sequence:to_matrix(names[:10],max_len=50)}).shape\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self,input,state):\n",
    "        return rnn_one_step(input[:,0],state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "\n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder('int32',(None,None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell,input_sequence[:,:,None],\n",
    "                                                 time_major=True,dtype='float32')\n",
    "\n",
    "print predicted_probas.eval({input_sequence:to_matrix(names[:10],max_len=50)}).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use the all the pre-implemented RNN cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in dir(tf.nn.rnn_cell)+dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print (obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder('int32',(None,None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence,last_state = tf.nn.dynamic_rnn(cell,inputs_embedded,dtype='float32')\n",
    "\n",
    "print('LSTM visible states[time,batch,unit]:', state_sequence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
